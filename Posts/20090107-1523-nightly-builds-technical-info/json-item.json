{"status":"ok","post":{"id":1210,"type":"post","slug":"nightly-builds-technical-info","url":"http:\/\/devhawk.net\/2009\/01\/07\/nightly-builds-technical-info\/","status":"publish","title":"Nightly Builds Technical Info","title_plain":"Nightly Builds Technical Info","content":"<p>Here are some technical details on my <a href=\"http:\/\/devhawk.net\/2009\/01\/07\/IronPython+Nightly+Builds.aspx\">Nightly Builds solution<\/a>. I broke them into a separate post because I figured most people are more interested in the actual service than how it\u2019s built.<\/p>\n<p>As you might expect, I built most of the solution in IronPython. All of the download, build, compress and Azure upload code was written in IPy. The one part I didn\u2019t write in IPy was the Azure cloud web app, which I wrote in C#. Jon Udell\u2019s been investigating <a href=\"http:\/\/blog.jonudell.net\/2008\/12\/22\/azure-calendar-aggregator-part-1\/\">getting IPy to run in Azure<\/a>, but I just wanted something quick and dirty (as you can see from the <a href=\"http:\/\/nightlybuilds.cloudapp.net\/\">utter lack of formatting<\/a>) so I decided to use C# instead. Man, were my ASP.NET skills rusty.<\/p>\n<p>As for the IronPython parts, for the most part I\u2019m using external tools for downloading, building and compressing. I use the <a href=\"http:\/\/www.codeplex.com\/IronPython\/Project\/ProjectRss.aspx?ProjectRSSFeed=codeplex%3a%2f%2fsourcecontrol%2fIronPython\">Source Control RSS Feed<\/a> to discover recent source code changesets, <a href=\"http:\/\/www.codeplex.com\/CodePlexClient\">CodePlex Client<\/a> to download source from CodePlex, <a href=\"http:\/\/msdn.microsoft.com\/en-us\/library\/wea2sca5.aspx\">MSBuild<\/a> to build the binaries, <a href=\"http:\/\/www.7-zip.org\/\">7-zip<\/a> to compress the binaries and the <a href=\"http:\/\/msdn.microsoft.com\/en-us\/library\/dd135716.aspx\">StorageClient library sample<\/a> to upload the compressed binaries up to Azure blob storage. <\/p>\n<p>For building and compressing, I\u2019m literally shelling out to MSBuild and 7-Zip via <a href=\"http:\/\/www.python.org\/doc\/2.5.2\/lib\/os-process.html\">os.system<\/a>. I looked at <a href=\"http:\/\/www.ironpython.info\/index.php\/Automating_MSBuild\">programmatically building<\/a> via the MSBuild API, but I ran into an <a href=\"http:\/\/blogs.microsoft.co.il\/blogs\/idof\/archive\/2008\/11\/24\/what-does-entity-framework-has-to-do-with-msbuild.aspx\">assembly binding bug<\/a> that I wasn\u2019t motivated enough to work around. As for creating zip files programmatically, IronPython doesn\u2019t have a <a href=\"http:\/\/www.python.org\/doc\/2.5.2\/lib\/module-zlib.html\">zlib module<\/a> implementation yet so I just used 7-Zip\u2019s command line utility instead.<\/p>\n<p>For downloading form CodePlex, I originally started by shelling out to CodePlex Client. However, I wanted the ability to cloak folders \u2013 for example Tutorial and SrcTests \u2013 that weren\u2019t required to build. CodePlex Client has a very useful TFS library embedded in it \u2013 the build process combines all the libraries into a single executable via <a href=\"http:\/\/www.microsoft.com\/downloads\/details.aspx?FamilyID=22914587-b4ad-4eae-87cf-b14ae6a939b0&amp;displaylang=en\">ILMerge<\/a>. I could have compiled my own version of the TFS library, but instead I just load cpc.exe as an assembly reference via clr.AddReferenceToFileAndPath. It\u2019s a nifty trick <a href=\"http:\/\/blogs.msdn.com\/hugunin\/\">Jim Hugunin<\/a> showed me once. <\/p>\n<p>Uploading to Azure was very straightforward because of the StorageClient library. Here\u2019s the code to create a blob container object (creating the actual blob container if it doesn\u2019t already exist) and to upload a file to a container.<\/p>\n<pre class=\"brush: python\">\ndef get_blob_container(prj):\n  azure_account = StorageAccountInfo(endpoint, None, azure_name, azure_key)\n  storage = BlobStorage.Create(azure_account)\n  container = storage.GetBlobContainer(prj.lower())\n  if not container.DoesContainerExist():\n    print \"Creating\", prj, \"Azure Blob Storage Container\"\n    container.CreateContainer(None, ContainerAccessControl.Public)\n  return container     \n\ndef upload_to_azure(container, upload_filepath, azure_filename, metadata):\n    print \"Uploading\", azure_filename, \"to Azure\"\n    prop = BlobProperties(azure_filename)\n    nv = NameValueCollection()\n    for key in metadata:\n      nv[key] = metadata[key]\n    prop.Metadata = nv     \n     \n    with File.OpenRead(upload_filepath) as stream:\n      contents = BlobContents(stream)\n      if not container.CreateBlob(prop, contents, True):\n        raise \"Uploading \" + azure_filename + \" to Azure failed\"\n<\/pre>\n<p>I\u2019ve been working on some pure IronPython code to access the <a href=\"http:\/\/msdn.microsoft.com\/en-us\/library\/dd179355.aspx\">blob storage REST API<\/a> directly, but that\u2019s primarily to familiarize myself with the service. At some point, I\u2019m going to want to leverage <a href=\"http:\/\/msdn.microsoft.com\/en-us\/library\/dd179423.aspx\">Table Storage<\/a> but my brief experimentation with the StorageClient Table Storage interface makes me think that it depends on static typing too much to be useful for IPy. If that turns out to be true, the Table Storage REST API will be my only option.<\/p>\n<p>As you can see in the code above, these Azure blob containers are set to be publically accessible (via ContainerAccessControl<span style=\"color: blue\">.<\/span>Public argument passed to CreateContainer). So for my C# app, I\u2019m simply using calling XDocument.Load with the <a href=\"http:\/\/msdn.microsoft.com\/en-us\/library\/dd135734.aspx\">List Blobs operation url<\/a>, shaping the results via LINQ to XML and binding them to nested ASP.NET Repeater controls. <\/p>\n<p>Assuming people find this useful, I\u2019m thinking of some additional improvements, in order of what I\u2019m likely to get to first:<\/p>\n<ul>\n<li>Caching Project Info in the cloud app      <br \/>Currently, I\u2019m hitting getting and processing the list of binary releases on every request. I\u2019m sure caching that data to make it more efficient. <\/li>\n<li>Virtual Build Environment      <br \/>Currently, I\u2019m just building on my laptop. It would be nice to have a clean environment dedicated to running the build script. <\/li>\n<li>Auto-Build      <br \/>My script uses the RSS feed to find the recent checkins, but I have to manually kick off the process. I\u2019d like it to set it up as a service that periodically checks the source code RSS feed automatically and downloads and builds any new releases that it finds. <\/li>\n<li>Table Storage for Build Metadata      <br \/>Today, I am simply grabbing the list of all uploaded compressed binaries for a given project, parsing their names, and displaying that as a hierarchical list on the <a href=\"http:\/\/nightlybuilds.cloudapp.net\/Project.aspx?project=ironpython\">project page<\/a>. If I used Table Storage, I could add additional metadata including social software features like ratings and comments. <\/li>\n<li>Amazon EC2 Virtual Build Environment      <br \/>If I\u2019m creating a virtual machine for my build environment, I could look at hosting it on <a href=\"http:\/\/aws.amazon.com\/ec2\/\">Amazon EC2<\/a>. They <a href=\"http:\/\/aws.amazon.com\/windows\/\">support Windows now<\/a> after all. Ideally, I\u2019d use an <a href=\"http:\/\/msdn.microsoft.com\/en-us\/library\/dd179341.aspx\">Azure worker role<\/a> for compiling and compressing builds, but our build tools need access to the file system. <\/li>\n<\/ul>\n","excerpt":"<p>Here are some technical details on my Nightly Builds solution. I broke them into a separate post because I figured most people are more interested in the actual service than how it\u2019s built. As you might expect, I built most of the solution in IronPython. All of the download, build, compress and Azure upload code [&hellip;]<\/p>\n","date":"2009-01-07 15:23:26","modified":"2009-01-07 15:23:26","categories":[{"id":252,"slug":"ironpython","title":"IronPython","description":"","parent":0,"post_count":99}],"tags":[{"id":277,"slug":"azure","title":"Azure","description":"","post_count":1}],"author":{"id":1,"slug":"admin","name":"DevHawk","first_name":"Harry","last_name":"Pierson","nickname":"DevHawk","url":"","description":""},"comments":[],"attachments":[],"comment_count":0,"comment_status":"closed","custom_fields":{"dasblog_entryid":["9ecbf637-0b38-475e-90ad-33af18381878"],"dasblog_compressedtitle":["Nightly+Builds+Technical+Info"],"dasblog_compressedtitleunique":["2009\/01\/07\/Nightly+Builds+Technical+Info"]}},"previous_url":"http:\/\/devhawk.net\/2009\/01\/07\/ironpython-nightly-builds\/","next_url":"http:\/\/devhawk.net\/2009\/01\/08\/kid-programming-with-kodu-coming-to-xbox-360\/"}