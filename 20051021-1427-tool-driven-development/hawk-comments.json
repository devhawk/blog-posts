[
  {
    "author-name": "David",
    "author-email": "",
    "author-url": "",
    "date": "2005-10-22T01:23:27-07:00",
    "content": "Yes, I fully agree. One big part of that seems integration with source code control to me. Often tools that are part of the build process are installed via an installer onto machines. This approach really breaks down, once you have rapid evolution of the tools, in sync with your project dev. I think making rapid changes in these small tools is important, but I also think that they will NOT be terribly backwards compatible, unlike huge languages like C#. So, I expect that tool T1 in version 3.0 will not be able to work on the models defined for building version 2.8, rather there would probably be a process to transform the model accordingly in version 2.9 (I am not sure whether I am very clear with this... Just generally I believe that the solution will be more to make sure each version of a small tool can handle input data from the previous version, but not to make sure each tool will be able to handle ALL old file format).\n\nSo, either those tools should be stored as binaries within source code control, so that if I check out a branch for an old version and build it uses the old version of the tool. Or, probably even better, it should build the tool as one of the first stepts with each full build and then use that dll/exe later on in the same build process. Good automation there would be incredibly helpful.\n\nAlso, this is very important for the VS IDE DSL editors created with the DSL Tool. Really what should happen is that if I check out a specific branch of my source code, the corresponding version of my custom DSL editor tool is dynamically loaded into the IDE. The approach I see right now to have a seperate install for the DSL that works across all versions within my source code depot is really not very usable, since it would require to be incredibly backwards compatible with my tools, which I don't really think brings any value for very small tools that might not be used across too many programs (and probably only internally too)."
  },
  {
    "author-name": "Jay Godse",
    "author-email": "jgodse@gmail.com",
    "author-url": "",
    "date": "2005-10-25T06:20:13-07:00",
    "content": "Although I would like to see a DSL for my domain, I don't think that tool-driven development is a natural extension of test-driven development. \n\nIn test-driven development, the goal is to define some functionality, define the tests, then build and test. Both the code and the unit tests are directly related to the specific release of a specific system. \n\nIn tool-driven development, the goal is essentially to codify domain expertise in some form of DSL and/or a tool to execute the transformations from model to code. This tool delivery is only indirectly related to the delivery of a specific product and specific release, and often imposes a cost that is cannot be borne by the budget of a specific release. \n\nThe tools are best left to a \"functional\" group of people who are responsible for developing, evolving, and sustaining the product or subsystem over multiple releases. They will build the domain expertise over time, and they are most likely to get extra money in their budget to develop a tool because it helps them meet their objectives of codifying domain expertise for current and future work. \n\nJay Godse\n\n\n"
  }
]