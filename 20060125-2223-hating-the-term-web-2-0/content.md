Now that I’m an [Architect on the
Edge](http://devhawk.net/2006/01/24/architect-on-the-edge/) (I’m
thinking of putting that on my business card. Good idea or bad idea?) of
course the first order of business is taking a closer look at “Web 2.0”.
One thing leaps out at me right away – I hate the name “Web 2.0”.

First off, it’s a pure marketing buzzword. It was originally coined as a
[conference name](http://www.web2con.com/). In a way, the fact that is
has no underlying meaning is a good thing, because it gives people
[argue](http://www.crunchnotes.com/?p=88) whether it
[really](http://blogs.zdnet.com/ip-telephony/?p=805) 
[exists](http://www.scripting.com/2005/12/19.html#busted)
or [not](http://www.readwriteweb.com/archives/web_20_is_dead.php/). In a
way, it’s like the word “multimedia” back when we were first putting
CD-ROMs into computers. There used to be lots of discussion if one thing
or another truly was “multimedia”. Now, we don’t really worry about
categorizing it as the marketing buzz around the term is long gone.

Secondly, I think it’s wildly arrogant to claim we’re only on version
2.0. The Internet has been around for 36 years. So everything before mid
2004 was Web 1.0 or earlier? And people are already talking about [Web
3.0](http://en.wikipedia.org/wiki/Web_3.0). Come on, let’s get real. The
technologies that are driving the current revolution have been
percolating for more than one major version of the underlying
technology.

Finally, what’s with the version number anyway? One of the core
principles Tim O’Reilly
[outlined](http://www.oreillynet.com/pub/a/oreilly/tim/news/2005/09/30/what-is-web-20.html)
was the “End of the Software Release Cycle”. Why are we using a holdover
from the software release cycle days to indicate the end of the software
release cycle?

Don’t get me wrong, I strongly believe that there is dramatic change
happening in this industry. The way I explain my new job is to consider
that one of the most basic axioms of distributed computing has been
overturned.

From day one, all the computing power has been focused in the center. At
first, the machines on the edge had no power at all – they were just
dumb terminals. Slowly but surely, those machines at the edge started to
become powerful in their own right. However, it’s only in the last seven
to ten years that commodity hardware that was pervasive on the edge grew
powerful enough to power the center. And it’s only in the last two or
three years that the connection between the center and the edge grew
fast and pervasive enough to make that edge power relevant.

The rules have changed. The power has shifted from the center to the
edge. And we’re only just beginning to see the effects.

Maybe we should call it WebNT?
:smile:

